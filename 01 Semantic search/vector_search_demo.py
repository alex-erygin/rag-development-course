import os
import glob
import chromadb
from chromadb.config import Settings
import openai
import re
from typing import List, Dict, Tuple
import json
from config import *

# –ò–º–ø–æ—Ä—Ç –≤—Å–µ—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏–∑ config.py

class VectorSearchDemo:
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        self.client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        self.collection = None
        self.openai_client = openai.OpenAI(
            base_url=EMBEDDING_MODEL_ENDPOINT,
            api_key=EMBEDDING_API_KEY
        )
        
    def get_text_files(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ KB"""
        pattern = os.path.join(KB_DIRECTORY, "*.txt")
        return glob.glob(pattern)
    
    def read_text_file(self, file_path: str) -> str:
        """–ß—Ç–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read().strip()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return ""
    
    def get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å"""
        try:
            response = self.openai_client.embeddings.create(
                model=EMBEDDING_MODEL_ID,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return []
    
    def create_collection(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ ChromaDB"""
        try:
            # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
            try:
                self.client.delete_collection(COLLECTION_NAME)
            except:
                pass
            
            self.collection = self.client.create_collection(
                name=COLLECTION_NAME,
                metadata={"description": "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ –∞–≤—Ç–æ–º–æ–±–∏–ª—å–Ω–æ–π —Ç–µ–º–∞—Ç–∏–∫–µ"}
            )
            print(f"–ö–æ–ª–ª–µ–∫—Ü–∏—è '{COLLECTION_NAME}' —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
    
    def index_documents(self):
        """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É"""
        if not self.collection:
            self.create_collection()
        
        text_files = self.get_text_files()
        if not text_files:
            print(f"–¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {KB_DIRECTORY}")
            return
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(text_files)} —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
        
        documents = []
        embeddings = []
        metadatas = []
        ids = []
        
        for file_path in text_files:
            content = self.read_text_file(file_path)
            if not content:
                continue
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = self.get_embedding(content)
            if not embedding:
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            filename = os.path.splitext(os.path.basename(file_path))[0]
            
            documents.append(content)
            embeddings.append(embedding)
            metadatas.append({
                "filename": filename,
                "file_path": file_path,
                "content_length": len(content)
            })
            ids.append(f"doc_{len(ids)}")
            
            print(f"–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω —Ñ–∞–π–ª: {filename}")
        
        if documents:
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            print(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        else:
            print("–ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
    
    def semantic_search(self, query: str, n_results: int = DEFAULT_SEARCH_RESULTS) -> List[Dict]:
        """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ"""
        if not self.collection:
            print("–ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.get_embedding(query)
            if not query_embedding:
                return []
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                include=["documents", "metadatas", "distances"]
            )
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            search_results = []
            for i in range(len(results['documents'][0])):
                search_results.append({
                    'content': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'distance': results['distances'][0][i],
                    'filename': results['metadatas'][0][i]['filename']
                })
            
            return search_results
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    def keyword_search(self, query: str, n_results: int = DEFAULT_SEARCH_RESULTS) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (—Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)"""
        if not self.collection:
            print("–ö–æ–ª–ª–µ–∫—Ü–∏—è –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            return []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            all_docs = self.collection.get()
            
            # –ò—â–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
            query_words = query.lower().split()
            search_results = []
            
            for i, doc in enumerate(all_docs['documents']):
                doc_lower = doc.lower()
                matches = 0
                
                for word in query_words:
                    if word in doc_lower:
                        matches += 1
                
                if matches > 0:
                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö —Å–ª–æ–≤
                    relevance = matches / len(query_words)
                    
                    search_results.append({
                        'content': doc,
                        'metadata': all_docs['metadatas'][i],
                        'relevance': relevance,
                        'filename': all_docs['metadatas'][i]['filename'],
                        'matches': matches
                    })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            search_results.sort(key=lambda x: x['relevance'], reverse=True)
            return search_results[:n_results]
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {e}")
            return []
    
    def print_search_results(self, results: List[Dict], search_type: str):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print(f"\n{'='*60}")
        print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–´ {search_type.upper()} –ü–û–ò–°–ö–ê")
        print(f"{'='*60}")
        
        if not results:
            print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. –§–∞–π–ª: {result['filename']}")
            if 'distance' in result:
                print(f"   –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {result['distance']:.4f}")
            if 'relevance' in result:
                print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {result['relevance']:.2f} ({result['matches']} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π)")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å–∏–º–≤–æ–ª—ã —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å–æ–≥–ª–∞—Å–Ω–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ
            content_preview = result['content'][:MAX_CONTENT_PREVIEW_LENGTH] + "..." if len(result['content']) > MAX_CONTENT_PREVIEW_LENGTH else result['content']
            print(f"   –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {content_preview}")
    
    def demo_search_comparison(self):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏ –∫–ª—é—á–µ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        test_queries = DEMO_QUERIES
        
        print("\n" + "="*80)
        print("–î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –°–†–ê–í–ù–ï–ù–ò–Ø –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û –ò –ö–õ–Æ–ß–ï–í–û–ì–û –ü–û–ò–°–ö–ê")
        print("="*80)
        
        for query in test_queries:
            print(f"\n\nüîç –ó–ê–ü–†–û–°: '{query}'")
            print("-" * 50)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫
            semantic_results = self.semantic_search(query, n_results=2)
            self.print_search_results(semantic_results, "–°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–û–ì–û")
            
            # –ö–ª—é—á–µ–≤–æ–π –ø–æ–∏—Å–∫
            keyword_results = self.keyword_search(query, n_results=2)
            self.print_search_results(keyword_results, "–ö–õ–Æ–ß–ï–í–û–ì–û")
            
            print("\n" + "-" * 50)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞
    search_system = VectorSearchDemo()
    
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    print("\nüìö –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    search_system.index_documents()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
    print("\nüéØ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–∏—Å–∫–∞...")
    search_system.demo_search_comparison()
    
    print("\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main() 